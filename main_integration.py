#!/usr/bin/env python3
"""
AlphaSeeker ä¸»é›†æˆåº”ç”¨
==================

AlphaSeekerç³»ç»Ÿçš„æ ¸å¿ƒé›†æˆåº”ç”¨ï¼Œåè°ƒæ‰€æœ‰ç»„ä»¶ï¼š
- é›†æˆAPIæœåŠ¡
- æœºå™¨å­¦ä¹ å¼•æ“
- å¤šç­–ç•¥ç®¡é“
- å¸‚åœºæ‰«æå™¨
- åŒé‡éªŒè¯å™¨

æä¾›ç»Ÿä¸€çš„ä½¿ç”¨æ¥å£å’Œå®Œæ•´çš„ç³»ç»Ÿç®¡ç†åŠŸèƒ½ã€‚

ä½œè€…: AlphaSeeker Team
ç‰ˆæœ¬: 1.0.0
æ—¥æœŸ: 2025-10-25
"""

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

import asyncio
import logging
import os
import sys
import signal
import time
import traceback
from contextlib import asynccontextmanager
from pathlib import Path
from typing import Dict, Any, Optional, List, Union
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
import json
import yaml
from concurrent.futures import ThreadPoolExecutor

# FastAPI and HTTP
from fastapi import FastAPI, HTTPException, BackgroundTasks, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.staticfiles import StaticFiles
import uvicorn

# é¡¹ç›®æ¨¡å—å¯¼å…¥
try:
    # APIæœåŠ¡
    from integrated_api.main import app as api_app, setup_logging as setup_api_logging
    
    # MLå¼•æ“
    from ml_engine import AlphaSeekerMLEngine, MODEL_CONFIG, RISK_CONFIG
    
    # ç®¡é“
    from pipeline import MultiStrategyPipeline, PipelineConfig, StrategyType
    from pipeline.types import (
        MarketData, TechnicalIndicators, MLPrediction, FusionResult,
        ScanRequest, ScanResult, SignalDirection
    )
    
    # æ‰«æå™¨
    from scanner import MarketScanner, ScanConfig, ScanStrategy
    
    # éªŒè¯å™¨
    from validation import (
        SignalValidationCoordinator, ValidationConfig, ValidationRequest,
        ValidationResult, ValidationPriority, LightGBMConfig, LLMConfig,
        FusionConfig, FusionStrategy, LLMProvider
    )
    
    print("âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
    
except ImportError as e:
    print(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿æ‰€æœ‰ä¾èµ–æ¨¡å—å·²æ­£ç¡®å®‰è£…")
    sys.exit(1)

# å…¨å±€é…ç½®
@dataclass
class AlphaSeekerConfig:
    """AlphaSeekerä¸»é…ç½®ç±»"""
    # åº”ç”¨åŸºç¡€é…ç½®
    app_name: str = "AlphaSeeker"
    app_version: str = "1.0.0"
    host: str = "0.0.0.0"
    port: int = 8000
    reload: bool = False
    debug: bool = False
    
    # ç»„ä»¶é…ç½®
    api_config: Dict[str, Any] = None
    ml_engine_config: Dict[str, Any] = None
    pipeline_config: Dict[str, Any] = None
    scanner_config: Dict[str, Any] = None
    validation_config: Dict[str, Any] = None
    
    # æ€§èƒ½é…ç½®
    max_concurrent_tasks: int = 32
    request_timeout: float = 30.0
    batch_size: int = 100
    enable_cache: bool = True
    
    # æ—¥å¿—é…ç½®
    log_level: str = "INFO"
    log_format: str = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    
    # æ•°æ®è·¯å¾„
    data_dir: str = "data"
    model_dir: str = "models"
    log_dir: str = "logs"
    cache_dir: str = "cache"
    
    def __post_init__(self):
        """åˆå§‹åŒ–åçš„é…ç½®å¤„ç†"""
        if self.api_config is None:
            self.api_config = self._default_api_config()
        if self.ml_engine_config is None:
            self.ml_engine_config = self._default_ml_config()
        if self.pipeline_config is None:
            self.pipeline_config = self._default_pipeline_config()
        if self.scanner_config is None:
            self.scanner_config = self._default_scanner_config()
        if self.validation_config is None:
            self.validation_config = self._default_validation_config()
    
    def _default_api_config(self) -> Dict[str, Any]:
        """é»˜è®¤APIé…ç½®"""
        return {
            "cors_origins": ["*"],
            "log_level": "INFO",
            "log_format": self.log_format,
            "host": self.host,
            "port": self.port,
            "reload": self.reload
        }
    
    def _default_ml_config(self) -> Dict[str, Any]:
        """é»˜è®¤MLå¼•æ“é…ç½®"""
        return {
            "model_config": MODEL_CONFIG,
            "risk_config": RISK_CONFIG,
            "enable_caching": self.enable_cache,
            "target_latency_ms": 500
        }
    
    def _default_pipeline_config(self) -> Dict[str, Any]:
        """é»˜è®¤ç®¡é“é…ç½®"""
        return {
            "max_concurrent_tasks": self.max_concurrent_tasks,
            "timeout_seconds": 10.0,
            "ml_probability_threshold": 0.65,
            "llm_confidence_threshold": 0.65,
            "strategy_weights": {
                StrategyType.TECHNICAL_INDICATOR: 0.4,
                StrategyType.ML_PREDICTION: 0.2,
                StrategyType.RISK_MODEL: 0.2,
                StrategyType.BACKTEST_REFERENCE: 0.2
            }
        }
    
    def _default_scanner_config(self) -> Dict[str, Any]:
        """é»˜è®¤æ‰«æå™¨é…ç½®"""
        return {
            "max_concurrent_tasks": self.max_concurrent_tasks,
            "scan_timeout": 15.0,
            "batch_size": self.batch_size,
            "enable_cache": self.enable_cache
        }
    
    def _default_validation_config(self) -> Dict[str, Any]:
        """é»˜è®¤éªŒè¯å™¨é…ç½®"""
        return {
            "max_concurrent_tasks": self.max_concurrent_tasks,
            "lgbm_config": LightGBMConfig(
                probability_threshold=0.65,
                confidence_threshold=0.6
            ),
            "llm_config": LLMConfig(
                provider=LLMProvider.OLLAMA,
                base_url="http://localhost:11434",
                model_name="llama2:13b"
            ),
            "fusion_config": FusionConfig(
                strategy=FusionStrategy.ADAPTIVE_WEIGHT,
                risk_reward_threshold=1.2
            )
        }

# ç³»ç»ŸçŠ¶æ€ç±»
@dataclass
class SystemStatus:
    """ç³»ç»ŸçŠ¶æ€ä¿¡æ¯"""
    status: str = "initializing"
    uptime: float = 0.0
    version: str = "1.0.0"
    components: Dict[str, Dict[str, Any]] = None
    performance: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.components is None:
            self.components = {}
        if self.performance is None:
            self.performance = {}

class AlphaSeekerOrchestrator:
    """AlphaSeekerç³»ç»Ÿåè°ƒå™¨ - æ ¸å¿ƒç»„ä»¶"""
    
    def __init__(self, config: AlphaSeekerConfig):
        """åˆå§‹åŒ–åè°ƒå™¨"""
        self.config = config
        self.logger = None
        self.start_time = None
        self.is_running = False
        
        # ç»„ä»¶å®ä¾‹
        self.ml_engine: Optional[AlphaSeekerMLEngine] = None
        self.pipeline: Optional[MultiStrategyPipeline] = None
        self.scanner: Optional[MarketScanner] = None
        self.validation_coordinator: Optional[SignalValidationCoordinator] = None
        
        # æ€§èƒ½ç»Ÿè®¡
        self.total_requests = 0
        self.successful_requests = 0
        self.failed_requests = 0
        self.total_processing_time = 0.0
        
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        self._create_directories()
    
    def _create_directories(self):
        """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
        directories = [
            self.config.data_dir,
            self.config.model_dir,
            self.config.log_dir,
            self.config.cache_dir
        ]
        
        for directory in directories:
            Path(directory).mkdir(parents=True, exist_ok=True)
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        log_level = getattr(logging, self.config.log_level.upper(), logging.INFO)
        
        # åˆ›å»ºæ ¼å¼åŒ–å™¨
        formatter = logging.Formatter(self.config.log_format)
        
        # æ–‡ä»¶å¤„ç†å™¨
        file_handler = logging.FileHandler(
            os.path.join(self.config.log_dir, "alphaseeker.log")
        )
        file_handler.setFormatter(formatter)
        
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setFormatter(formatter)
        
        # é…ç½®æ ¹æ—¥å¿—å™¨
        root_logger = logging.getLogger()
        root_logger.setLevel(log_level)
        root_logger.handlers.clear()
        root_logger.addHandler(file_handler)
        root_logger.addHandler(console_handler)
        
        # è®¾ç½®ç¬¬ä¸‰æ–¹åº“çš„æ—¥å¿—çº§åˆ«
        logging.getLogger("ccxt").setLevel(logging.WARNING)
        logging.getLogger("urllib3").setLevel(logging.WARNING)
        logging.getLogger("aiohttp").setLevel(logging.WARNING)
        logging.getLogger("lightgbm").setLevel(logging.WARNING)
        
        self.logger = logging.getLogger(__name__)
        self.logger.info("ğŸ“ æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    async def initialize_components(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        try:
            self.logger.info("ğŸš€ å¼€å§‹åˆå§‹åŒ–AlphaSeekerç»„ä»¶...")
            
            # 1. åˆå§‹åŒ–MLå¼•æ“
            self.logger.info("ğŸ§  åˆå§‹åŒ–æœºå™¨å­¦ä¹ å¼•æ“...")
            self.ml_engine = AlphaSeekerMLEngine(
                config=self.config.ml_engine_config,
                logger=self.logger
            )
            ml_health = self.ml_engine.health_check()
            self.logger.info(f"MLå¼•æ“çŠ¶æ€: {ml_health['overall_status']}")
            
            # 2. åˆå§‹åŒ–éªŒè¯å™¨
            self.logger.info("ğŸ” åˆå§‹åŒ–åŒé‡éªŒè¯å™¨...")
            validation_config = ValidationConfig(**self.config.validation_config)
            self.validation_coordinator = SignalValidationCoordinator(validation_config)
            
            # 3. åˆå§‹åŒ–ç®¡é“
            self.logger.info("âš™ï¸ åˆå§‹åŒ–å¤šç­–ç•¥ç®¡é“...")
            pipeline_config = PipelineConfig(**self.config.pipeline_config)
            self.pipeline = MultiStrategyPipeline(pipeline_config)
            await self.pipeline.start()
            
            # 4. åˆå§‹åŒ–æ‰«æå™¨
            self.logger.info("ğŸ“Š åˆå§‹åŒ–å¸‚åœºæ‰«æå™¨...")
            scan_config = ScanConfig(**self.config.scanner_config)
            self.scanner = MarketScanner(scan_config)
            
            # æ›´æ–°ç»„ä»¶çŠ¶æ€
            self._update_component_status("ml_engine", "ready", ml_health)
            self._update_component_status("validation", "ready", {"status": "ready"})
            self._update_component_status("pipeline", "ready", {"status": "ready"})
            self._update_component_status("scanner", "ready", {"status": "ready"})
            
            self.logger.info("âœ… æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"âŒ ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            self.logger.error(traceback.format_exc())
            raise
    
    def _update_component_status(self, component: str, status: str, details: Dict[str, Any]):
        """æ›´æ–°ç»„ä»¶çŠ¶æ€"""
        if not hasattr(self, '_component_status'):
            self._component_status = {}
        
        self._component_status[component] = {
            "status": status,
            "last_update": datetime.now().isoformat(),
            "details": details
        }
    
    def get_system_status(self) -> SystemStatus:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        uptime = time.time() - self.start_time if self.start_time else 0.0
        
        # æ”¶é›†å„ç»„ä»¶çŠ¶æ€
        components = {}
        
        # MLå¼•æ“çŠ¶æ€
        if self.ml_engine:
            ml_health = self.ml_engine.health_check()
            components["ml_engine"] = {
                "status": "healthy" if ml_health['overall_status'] == "healthy" else "warning",
                "performance": self.ml_engine.get_performance_stats()
            }
        
        # éªŒè¯å™¨çŠ¶æ€
        if self.validation_coordinator:
            components["validation"] = self._component_status.get("validation", {"status": "unknown"})
        
        # ç®¡é“çŠ¶æ€
        if self.pipeline:
            components["pipeline"] = self._component_status.get("pipeline", {"status": "unknown"})
        
        # æ‰«æå™¨çŠ¶æ€
        if self.scanner:
            components["scanner"] = self._component_status.get("scanner", {"status": "unknown"})
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        success_rate = (self.successful_requests / max(self.total_requests, 1)) * 100
        avg_processing_time = self.total_processing_time / max(self.total_requests, 1)
        
        performance = {
            "total_requests": self.total_requests,
            "successful_requests": self.successful_requests,
            "failed_requests": self.failed_requests,
            "success_rate": round(success_rate, 2),
            "avg_processing_time": round(avg_processing_time, 3),
            "uptime": round(uptime, 2)
        }
        
        return SystemStatus(
            status="healthy" if self.is_running else "stopped",
            uptime=uptime,
            version=self.config.app_version,
            components=components,
            performance=performance
        )
    
    async def start(self):
        """å¯åŠ¨ç³»ç»Ÿ"""
        try:
            self.start_time = time.time()
            self._setup_logging()
            self.logger.info(f"ğŸš€ å¯åŠ¨ AlphaSeeker v{self.config.app_version}")
            
            # åˆå§‹åŒ–ç»„ä»¶
            await self.initialize_components()
            
            self.is_running = True
            self.logger.info("âœ… AlphaSeekerç³»ç»Ÿå¯åŠ¨å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"âŒ ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {e}")
            self.logger.error(traceback.format_exc())
            raise
    
    async def stop(self):
        """åœæ­¢ç³»ç»Ÿ"""
        self.logger.info("ğŸ›‘ æ­£åœ¨åœæ­¢AlphaSeekerç³»ç»Ÿ...")
        
        self.is_running = False
        
        # åœæ­¢å„ç»„ä»¶
        try:
            if self.pipeline:
                await self.pipeline.stop()
            
            if self.validation_coordinator:
                await self.validation_coordinator.shutdown()
            
            self.logger.info("âœ… AlphaSeekerç³»ç»Ÿå·²åœæ­¢")
            
        except Exception as e:
            self.logger.error(f"âŒ åœæ­¢ç³»ç»Ÿæ—¶å‡ºé”™: {e}")
    
    async def process_trading_signal(self, symbol: str, market_data: Dict[str, Any], 
                                   indicators: Dict[str, Any], 
                                   features: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†äº¤æ˜“ä¿¡å· - æ ¸å¿ƒåŠŸèƒ½"""
        start_time = time.time()
        self.total_requests += 1
        
        try:
            self.logger.info(f"ğŸ“Š å¤„ç† {symbol} çš„äº¤æ˜“ä¿¡å·")
            
            # 1. MLå¼•æ“é¢„æµ‹
            ml_prediction = None
            if self.ml_engine:
                ml_result = self.ml_engine.predict(market_data)
                ml_prediction = MLPrediction(
                    label=ml_result['signal_label'],
                    probability_scores=ml_result['probability_distribution'],
                    confidence=ml_result['confidence'],
                    model_version="lightgbm_v2.1.0"
                )
            
            # 2. å¸‚åœºæ•°æ®è½¬æ¢
            market = MarketData(
                symbol=symbol,
                timestamp=datetime.now(),
                price=market_data.get('price', 0),
                volume=market_data.get('volume', 0),
                data_freshness=1.0
            )
            
            # 3. æŠ€æœ¯æŒ‡æ ‡è½¬æ¢
            technical_indicators = TechnicalIndicators(
                rsi=indicators.get('rsi', 50),
                macd=indicators.get('macd', 0),
                adx=indicators.get('adx', 25),
                sma_50=indicators.get('sma_50', 0),
                sma_200=indicators.get('sma_200', 0)
            )
            
            # 4. å¤šç­–ç•¥èåˆ
            fusion_result = None
            if self.pipeline and ml_prediction:
                fusion_result = await self.pipeline.process_single_symbol(
                    symbol=symbol,
                    market_data=market,
                    technical_indicators=technical_indicators,
                    ml_prediction=ml_prediction
                )
            
            # 5. åŒé‡éªŒè¯
            validation_result = None
            if self.validation_coordinator:
                validation_request = ValidationRequest(
                    symbol=symbol,
                    timeframe="1h",
                    current_price=market_data.get('price', 0),
                    features=features,
                    indicators=indicators,
                    risk_context={"volatility": 0.025},
                    priority=ValidationPriority.MEDIUM
                )
                
                validation_result = await self.validation_coordinator.validate_signal(validation_request)
            
            # 6. åˆæˆæœ€ç»ˆç»“æœ
            final_result = {
                "symbol": symbol,
                "timestamp": datetime.now().isoformat(),
                "signal_direction": fusion_result.final_direction.value if fusion_result else "unknown",
                "confidence": fusion_result.combined_confidence if fusion_result else 0.5,
                "score": fusion_result.final_score if fusion_result else 0.5,
                "risk_reward_ratio": fusion_result.risk_reward_ratio if fusion_result else 1.0,
                "processing_time": time.time() - start_time,
                "components": {
                    "ml_prediction": {
                        "label": ml_prediction.label if ml_prediction else None,
                        "confidence": ml_prediction.confidence if ml_prediction else None,
                        "probabilities": ml_prediction.probability_scores if ml_prediction else None
                    },
                    "fusion_result": {
                        "final_score": fusion_result.final_score if fusion_result else None,
                        "confidence": fusion_result.combined_confidence if fusion_result else None
                    } if fusion_result else None,
                    "validation": {
                        "status": validation_result.status.value if validation_result else None,
                        "combined_score": validation_result.combined_score if validation_result else None
                    } if validation_result else None
                }
            }
            
            self.successful_requests += 1
            self.total_processing_time += time.time() - start_time
            
            self.logger.info(f"âœ… {symbol} ä¿¡å·å¤„ç†å®Œæˆ - æ–¹å‘: {final_result['signal_direction']}, ç½®ä¿¡åº¦: {final_result['confidence']:.3f}")
            
            return final_result
            
        except Exception as e:
            self.failed_requests += 1
            self.logger.error(f"âŒ {symbol} ä¿¡å·å¤„ç†å¤±è´¥: {e}")
            self.logger.error(traceback.format_exc())
            raise
    
    async def batch_scan_market(self, symbols: List[str], max_results: int = 10) -> Dict[str, Any]:
        """æ‰¹é‡å¸‚åœºæ‰«æ"""
        start_time = time.time()
        
        try:
            self.logger.info(f"ğŸ” å¼€å§‹æ‰¹é‡æ‰«æå¸‚åœº - {len(symbols)} ä¸ªäº¤æ˜“å¯¹")
            
            results = []
            
            # å¹¶å‘å¤„ç†å¤šä¸ªäº¤æ˜“å¯¹
            tasks = []
            for symbol in symbols:
                # æ¨¡æ‹Ÿå¸‚åœºæ•°æ®ï¼ˆå®é™…ä¸­åº”ä»æ•°æ®æºè·å–ï¼‰
                mock_market_data = {
                    "price": 40000 + hash(symbol) % 10000,
                    "volume": 1000000,
                    "timestamp": time.time()
                }
                
                mock_indicators = {
                    "rsi": 50 + hash(symbol) % 40,
                    "macd": 100 + hash(symbol) % 200,
                    "adx": 20 + hash(symbol) % 20,
                    "sma_50": 42000,
                    "sma_200": 40000
                }
                
                mock_features = {
                    "mid_price": mock_market_data["price"],
                    "spread": 2.5,
                    "volatility_60s": 0.025
                }
                
                task = self.process_trading_signal(
                    symbol, mock_market_data, mock_indicators, mock_features
                )
                tasks.append(task)
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            symbol_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # è¿‡æ»¤å’Œå¤„ç†ç»“æœ
            valid_results = []
            for i, result in enumerate(symbol_results):
                if isinstance(result, Exception):
                    self.logger.error(f"å¤„ç† {symbols[i]} æ—¶å‡ºé”™: {result}")
                    continue
                
                # åªä¿ç•™é«˜ç½®ä¿¡åº¦çš„ç»“æœ
                if result['confidence'] >= 0.6:
                    valid_results.append(result)
            
            # æŒ‰ç½®ä¿¡åº¦æ’åºï¼Œå–å‰max_resultsä¸ª
            valid_results.sort(key=lambda x: x['confidence'], reverse=True)
            results = valid_results[:max_results]
            
            processing_time = time.time() - start_time
            
            final_result = {
                "scan_id": f"scan_{int(time.time())}",
                "timestamp": datetime.now().isoformat(),
                "total_symbols": len(symbols),
                "processed_symbols": len(symbol_results),
                "valid_results": len(results),
                "results": results,
                "processing_time": processing_time,
                "summary": {
                    "avg_confidence": sum(r['confidence'] for r in results) / max(len(results), 1),
                    "signal_distribution": self._analyze_signal_distribution(results)
                }
            }
            
            self.logger.info(f"âœ… å¸‚åœºæ‰«æå®Œæˆ - å¤„ç†: {len(symbol_results)}ä¸ª, æœ‰æ•ˆ: {len(results)}ä¸ª, ç”¨æ—¶: {processing_time:.2f}ç§’")
            
            return final_result
            
        except Exception as e:
            self.logger.error(f"âŒ å¸‚åœºæ‰«æå¤±è´¥: {e}")
            self.logger.error(traceback.format_exc())
            raise
    
    def _analyze_signal_distribution(self, results: List[Dict[str, Any]]) -> Dict[str, int]:
        """åˆ†æä¿¡å·åˆ†å¸ƒ"""
        distribution = {"long": 0, "short": 0, "flat": 0, "unknown": 0}
        
        for result in results:
            direction = result.get("signal_direction", "unknown")
            distribution[direction] = distribution.get(direction, 0) + 1
        
        return distribution


# å…¨å±€ç³»ç»Ÿå®ä¾‹
orchestrator: Optional[AlphaSeekerOrchestrator] = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    global orchestrator
    
    # å¯åŠ¨
    try:
        orchestrator = AlphaSeekerOrchestrator(CONFIG)
        await orchestrator.start()
        
        yield
        
    finally:
        # å…³é—­
        if orchestrator:
            await orchestrator.stop()

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="AlphaSeekeré›†æˆç³»ç»Ÿ",
    description="AlphaSeeker AIé©±åŠ¨çš„åŠ å¯†è´§å¸äº¤æ˜“ä¿¡å·ç³»ç»Ÿï¼Œé›†æˆæœºå™¨å­¦ä¹ ã€å¤šç­–ç•¥èåˆå’ŒåŒé‡éªŒè¯",
    version="1.0.0",
    lifespan=lifespan
)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€é…ç½®å®ä¾‹
CONFIG = AlphaSeekerConfig()

@app.on_event("startup")
async def startup_event():
    """å¯åŠ¨äº‹ä»¶"""
    print("ğŸš€ AlphaSeekeré›†æˆç³»ç»Ÿæ­£åœ¨å¯åŠ¨...")

@app.on_event("shutdown")
async def shutdown_event():
    """å…³é—­äº‹ä»¶"""
    print("ğŸ›‘ AlphaSeekeré›†æˆç³»ç»Ÿæ­£åœ¨å…³é—­...")

@app.get("/", tags=["ç³»ç»Ÿ"])
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "name": "AlphaSeekeré›†æˆç³»ç»Ÿ",
        "version": "1.0.0",
        "description": "AIé©±åŠ¨çš„åŠ å¯†è´§å¸äº¤æ˜“ä¿¡å·ç³»ç»Ÿ",
        "components": [
            "æœºå™¨å­¦ä¹ å¼•æ“ (LightGBM)",
            "å¤šç­–ç•¥ä¿¡å·ç®¡é“",
            "å¸‚åœºæ‰«æå™¨",
            "åŒé‡éªŒè¯å™¨",
            "é›†æˆAPIæœåŠ¡"
        ],
        "status": "running",
        "timestamp": datetime.now().isoformat()
    }

@app.get("/health", tags=["ç³»ç»Ÿ"])
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    if not orchestrator or not orchestrator.is_running:
        raise HTTPException(status_code=503, detail="ç³»ç»Ÿæœªè¿è¡Œ")
    
    try:
        status = orchestrator.get_system_status()
        return status
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}")

@app.post("/api/v1/signal/analyze", tags=["äº¤æ˜“ä¿¡å·"])
async def analyze_signal(request: Request):
    """åˆ†æå•ä¸ªäº¤æ˜“ä¿¡å·"""
    if not orchestrator or not orchestrator.is_running:
        raise HTTPException(status_code=503, detail="ç³»ç»Ÿæœªè¿è¡Œ")
    
    try:
        data = await request.json()
        
        required_fields = ["symbol", "market_data", "indicators", "features"]
        for field in required_fields:
            if field not in data:
                raise HTTPException(status_code=400, detail=f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
        
        result = await orchestrator.process_trading_signal(
            symbol=data["symbol"],
            market_data=data["market_data"],
            indicators=data["indicators"],
            features=data["features"]
        )
        
        return result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ä¿¡å·åˆ†æå¤±è´¥: {str(e)}")

@app.post("/api/v1/scan/market", tags=["å¸‚åœºæ‰«æ"])
async def scan_market(request: Request):
    """æ‰¹é‡å¸‚åœºæ‰«æ"""
    if not orchestrator or not orchestrator.is_running:
        raise HTTPException(status_code=503, detail="ç³»ç»Ÿæœªè¿è¡Œ")
    
    try:
        data = await request.json()
        
        symbols = data.get("symbols", [])
        max_results = data.get("max_results", 10)
        
        if not symbols:
            raise HTTPException(status_code=400, detail="symbolsä¸èƒ½ä¸ºç©º")
        
        if len(symbols) > 100:  # é™åˆ¶æœ€å¤§æ•°é‡
            raise HTTPException(status_code=400, detail="symbolsæ•°é‡ä¸èƒ½è¶…è¿‡100ä¸ª")
        
        result = await orchestrator.batch_scan_market(symbols, max_results)
        
        return result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¸‚åœºæ‰«æå¤±è´¥: {str(e)}")

@app.get("/api/v1/system/status", tags=["ç³»ç»Ÿ"])
async def get_system_status():
    """è·å–è¯¦ç»†ç³»ç»ŸçŠ¶æ€"""
    if not orchestrator or not orchestrator.is_running:
        raise HTTPException(status_code=503, detail="ç³»ç»Ÿæœªè¿è¡Œ")
    
    try:
        status = orchestrator.get_system_status()
        return asdict(status)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {str(e)}")

@app.get("/api/v1/components", tags=["ç³»ç»Ÿ"])
async def get_components_info():
    """è·å–ç»„ä»¶ä¿¡æ¯"""
    components_info = {
        "ml_engine": {
            "name": "æœºå™¨å­¦ä¹ å¼•æ“",
            "description": "LightGBMæ¨¡å‹è¿›è¡Œäº¤æ˜“ä¿¡å·é¢„æµ‹",
            "features": ["ä»·æ ¼é¢„æµ‹", "ç‰¹å¾å·¥ç¨‹", "é£é™©ç®¡ç†"]
        },
        "pipeline": {
            "name": "å¤šç­–ç•¥ç®¡é“",
            "description": "èåˆå¤šç§ç­–ç•¥çš„äº¤æ˜“ä¿¡å·å¤„ç†ç®¡é“",
            "features": ["ç­–ç•¥èåˆ", "ä¿¡å·ä¼˜å…ˆçº§", "å†²çªè§£å†³"]
        },
        "scanner": {
            "name": "å¸‚åœºæ‰«æå™¨",
            "description": "å¤šç­–ç•¥å¸‚åœºæ‰«æå’Œæœºä¼šå‘ç°",
            "features": ["æ‰¹é‡æ‰«æ", "ç­–ç•¥å¤šæ ·åŒ–", "æœºä¼šæ’åº"]
        },
        "validation": {
            "name": "åŒé‡éªŒè¯å™¨",
            "description": "LightGBM + LLMåŒé‡éªŒè¯æœºåˆ¶",
            "features": ["å¿«é€Ÿç­›é€‰", "æ·±åº¦è¯„ä¼°", "ç»“æœèåˆ"]
        },
        "api": {
            "name": "é›†æˆAPI",
            "description": "ç»Ÿä¸€çš„REST APIæ¥å£æœåŠ¡",
            "features": ["REST API", "CORSæ”¯æŒ", "é”™è¯¯å¤„ç†"]
        }
    }
    
    return {
        "components": components_info,
        "version": "1.0.0",
        "timestamp": datetime.now().isoformat()
    }

@app.get("/api/v1/performance", tags=["ç³»ç»Ÿ"])
async def get_performance_metrics():
    """è·å–æ€§èƒ½æŒ‡æ ‡"""
    if not orchestrator:
        raise HTTPException(status_code=503, detail="ç³»ç»Ÿæœªè¿è¡Œ")
    
    try:
        status = orchestrator.get_system_status()
        
        return {
            "performance": status.performance,
            "system_info": {
                "uptime": status.uptime,
                "version": status.version,
                "config": {
                    "max_concurrent_tasks": CONFIG.max_concurrent_tasks,
                    "batch_size": CONFIG.batch_size,
                    "enable_cache": CONFIG.enable_cache
                }
            },
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æ€§èƒ½æŒ‡æ ‡å¤±è´¥: {str(e)}")

# å¼‚å¸¸å¤„ç†å™¨
@app.exception_handler(HTTPException)
async def http_exception_handler(request, exc):
    """HTTPå¼‚å¸¸å¤„ç†"""
    return JSONResponse(
        status_code=exc.status_code,
        content={"error": exc.detail, "status_code": exc.status_code}
    )

@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    """é€šç”¨å¼‚å¸¸å¤„ç†"""
    return JSONResponse(
        status_code=500,
        content={"error": "å†…éƒ¨æœåŠ¡å™¨é”™è¯¯", "status_code": 500}
    )

def signal_handler(signum, frame):
    """ä¿¡å·å¤„ç†å™¨"""
    print(f"\nğŸ›‘ æ¥æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨å…³é—­ç³»ç»Ÿ...")
    if orchestrator:
        asyncio.create_task(orchestrator.stop())
    sys.exit(0)

def setup_signal_handlers():
    """è®¾ç½®ä¿¡å·å¤„ç†å™¨"""
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

def main():
    """ä¸»å‡½æ•°"""
    setup_signal_handlers()
    
    print("=" * 60)
    print("ğŸš€ AlphaSeeker é›†æˆç³»ç»Ÿ")
    print("=" * 60)
    print(f"ç‰ˆæœ¬: {CONFIG.app_version}")
    print(f"ä¸»æœº: {CONFIG.host}:{CONFIG.port}")
    print(f"è°ƒè¯•: {CONFIG.debug}")
    print(f"å¹¶å‘ä»»åŠ¡: {CONFIG.max_concurrent_tasks}")
    print(f"æ‰¹å¤„ç†å¤§å°: {CONFIG.batch_size}")
    print("=" * 60)
    
    # å¯åŠ¨æœåŠ¡å™¨
    uvicorn.run(
        "main_integration:app",
        host=CONFIG.host,
        port=CONFIG.port,
        reload=CONFIG.reload,
        log_level=CONFIG.log_level.lower()
    )

if __name__ == "__main__":
    main()